In this project, we created a program that uses computer vision techniques and artificial
intelligence (AI) libraries to enable users to control their computer mouse through specific hand
gestures. This approach focuses on enhancing accessibility for individuals who may have
difficulty controlling a standard mouse. Some of the libraries used include:

	● OpenCV: A core component for capturing video from the webcam, image processing, and displaying the output to the user.
	● MediaPipe: Provides robust models for hand tracking, playing a critical role in identifying hand landmarks in real-time.
	● PyAutoGUI: Empowers the system to simulate mouse movements and clicks, translating the hand gestures into actionable commands.
	● NumPy: Assists in complex numerical operations, including coordinate transformations and the implementation of smoothing algorithms for stable output.
 
